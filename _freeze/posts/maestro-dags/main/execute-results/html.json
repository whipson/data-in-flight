{
  "hash": "f1003d1a28de2e23d939440101f67725",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Chain your maestro pipelines DAG style\"\nsubtitle: Version 0.4.0 introduces tags for creating connected pipelines\nauthor: \"Will Hipson\"\ndate: \"2024-11-22\"\ndate-modified: last-modified\ncategories: [R, data pipelines, orchestration, maestro, packages, release]\noutput: html\n---\n\n\n\nI'm thrilled to introduce the biggest maestro update yet. DAGs! A DAG (directed acyclic graph) in the context of data pipelines is when you have data processing steps that connect into other steps until a final step is reached. Almost all data orchestration platforms use the concept of DAGs to increase reusability and isolation of discrete components. As of maestro 0.4.0, DAGs are now possible using `maestroInputs` and `maestroOutputs` tags. This post will go through the motivation and implementation of this new feature.\n\nIf you haven't heard of maestro, it's a package that helps you schedule your R scripts all in a single project using tags. You can learn more about it [here](../hello-maestro/hello-maestro.qmd).\n\nGet it from CRAN:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ninstall.packages(\"maestro\")\n```\n:::\n\n\n\n## Why DAGs?\n\nLet's imagine we have a data pipeline where we want to extract data, clean/transform it, train a model, and send the predictions to a database. We can take each of these steps and chain them together so that the output of 'extract' is automatically fed into 'clean/transform', and so on.\n\nThe advantage of doing this in maestro is that you get better observability and retracability along each step. As we'll see, we can more clearly identify where errors occur and even recover intermediate results.\n\n## DAGs in maestro\n\nIn short, a DAG pipeline is created using either `maestroInputs` or `maestroOutputs` tags. Both are valid but usually only one is needed. Simply put, a pipeline with a tag `#' @maestroInputs start_pipe` receives the output from a pipeline called `start_pipe`. Alternatively, we could use `#' @maestroOutputs end_pipe` to indicate that the pipeline called `end_pipe` receives the input of the current pipeline.\n\nLet's see an example where we make model predictions on the `nycflights13` data.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#' /pipelines/model_flights.R\n#' @maestroFrequency daily\n#' @maestroStartTime 2024-11-22 09:00:00\n#' @maestroOutputs process_flights\nextract_flights <- function() {\n  \n  # Imagine this is from a source where the data changes\n  nycflights13::flights\n}\n\n#' @maestroOutputs train_model\nprocess_flights <- function(.input) {\n  \n  daily_flights <- .input |> \n    dplyr::mutate(date = lubridate::make_date(year, month, day)) |> \n    dplyr::summarise(\n      n_flights = dplyr::n(), .by = date\n    )\n  \n  # A simple time series\n  ts(data = daily_flights$n_flights, frequency = 365)\n}\n\n#' @maestroOutputs forecast_flights\ntrain_model <- function(.input) {\n  \n  # A simple ARIMA model (using the {forecast} package would be better)\n  .input |> \n    arima(order = c(1, 1, 1))\n}\n\n#' @maestro\nforecast_flights <- function(.input) {\n  \n  # Forecast the next 7 days\n  pred_obj <- predict(.input, n.ahead = 7)\n  pred_obj$pred\n}\n```\n:::\n\n\n\nWe won't focus much on the content of the functions. Instead, pay attention to the use of `maestroOutputs`. Each function that outputs into another references the name of that function. The last function `forecast_flights` just uses a generic `#' @maestro` tag to indicate that it is part of the maestro project. Also note the use of the special keyword `.input`. This argument must be supplied to all functions receiving an input. Use this argument to capture the data being passed each step along the pipeline.\n\nNow we can build the schedule like always.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# /orchestrator.R\nlibrary(maestro)\n\nschedule <- build_schedule(quiet = TRUE)\n```\n:::\n\n\n\nWe can verify that the DAG is properly defined using the `show_network()` function on our newly created schedule.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nshow_network(schedule)\n```\n\n::: {.cell-output-display}\n\n```{=html}\n<div class=\"grViz html-widget html-fill-item\" id=\"htmlwidget-f479831f88694cd7c32c\" style=\"width:100%;height:464px;\"></div>\n<script type=\"application/json\" data-for=\"htmlwidget-f479831f88694cd7c32c\">{\"x\":{\"diagram\":\"digraph {\\n\\ngraph [layout = \\\"neato\\\",\\n       outputorder = \\\"edgesfirst\\\",\\n       bgcolor = \\\"white\\\"]\\n\\nnode [fontname = \\\"Helvetica\\\",\\n      fontsize = \\\"10\\\",\\n      shape = \\\"circle\\\",\\n      fixedsize = \\\"true\\\",\\n      width = \\\"0.5\\\",\\n      style = \\\"filled\\\",\\n      fillcolor = \\\"aliceblue\\\",\\n      color = \\\"gray70\\\",\\n      fontcolor = \\\"gray50\\\"]\\n\\nedge [fontname = \\\"Helvetica\\\",\\n     fontsize = \\\"8\\\",\\n     len = \\\"1.5\\\",\\n     color = \\\"gray80\\\",\\n     arrowsize = \\\"0.5\\\"]\\n\\n  \\\"1\\\" [label = \\\"extract_flights\\\", fillcolor = \\\"#F0F8FF\\\", fontcolor = \\\"#000000\\\", pos = \\\"0,4!\\\"] \\n  \\\"2\\\" [label = \\\"process_flights\\\", fillcolor = \\\"#F0F8FF\\\", fontcolor = \\\"#000000\\\", pos = \\\"0,3!\\\"] \\n  \\\"3\\\" [label = \\\"train_model\\\", fillcolor = \\\"#F0F8FF\\\", fontcolor = \\\"#000000\\\", pos = \\\"0,2!\\\"] \\n  \\\"4\\\" [label = \\\"forecast_flights\\\", fillcolor = \\\"#F0F8FF\\\", fontcolor = \\\"#000000\\\", pos = \\\"0,1!\\\"] \\n  \\\"1\\\"->\\\"2\\\" \\n  \\\"2\\\"->\\\"3\\\" \\n  \\\"3\\\"->\\\"4\\\" \\n}\",\"config\":{\"engine\":\"dot\",\"options\":null}},\"evals\":[],\"jsHooks\":[]}</script>\n```\n\n:::\n:::\n\n\n\nNow we can run the schedule. For testing purposes, we'll set `run_all = TRUE` so that the pipeline runs no matter what the scheduling is.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrun_schedule(\n  schedule,\n  run_all = TRUE\n)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\n\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\n── [2024-11-22 14:25:11]\nRunning pipelines ▶ \n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nℹ extract_flights\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\n✔ extract_flights [768ms]\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\n\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nℹ |-process_flights\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\n✔ |-process_flights [24ms]\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\n\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nℹ   |-train_model\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\n✔   |-train_model [9ms]\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\n\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nℹ   |-  |-forecast_flights\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\n✔   |-  |-forecast_flights [5ms]\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\n\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\n── [2024-11-22 14:25:11]\nPipeline execution completed ■ | 0.833 sec elapsed \n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\n✔ 4 successes | → 0 skipped | ! 0 warnings | ✖ 0 errors | ◼ 4 total\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\n────────────────────────────────────────────────────────────────────────────────\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\n\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\n── Maestro Schedule with 4 pipelines:  \n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\n• Success\n```\n\n\n:::\n:::\n\n\nWe can see from the console output that the whole pipeline ran successfully. If we want to get the output from each of the steps, we can use `get_artifacts()`. This returns intermediate results too, which can be helpful if you want to retrieve state after a failed run of the schedule.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nartifacts <- get_artifacts(schedule)\nartifacts$forecast_flights\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nTime Series:\nStart = c(2, 1) \nEnd = c(2, 7) \nFrequency = 365 \n[1] 942.7232 934.9722 933.7773 933.5931 933.5647 933.5603 933.5596\n```\n\n\n:::\n:::\n\n\nMaestro can be used to create any valid DAG (e.g., branching, joining, etc.). I hope this new addition to maestro super charges your data orchestration.\n\nCheck out the [release notes](https://whipson.github.io/maestro/news/index.html) for more details on what's new in version 0.4.0. If you find any bugs or want to suggest new features and improvements, please add them [here](https://github.com/whipson/maestro/issues) or reach out to me on [LinkedIn](https://www.linkedin.com/in/will-hipson/).\n\nHappy orchestrating!\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<link href=\"../../site_libs/htmltools-fill-0.5.8.1/fill.css\" rel=\"stylesheet\" />\n<script src=\"../../site_libs/htmlwidgets-1.6.4/htmlwidgets.js\"></script>\n<script src=\"../../site_libs/viz-1.8.2/viz.js\"></script>\n<link href=\"../../site_libs/DiagrammeR-styles-0.2/styles.css\" rel=\"stylesheet\" />\n<script src=\"../../site_libs/grViz-binding-1.0.11/grViz.js\"></script>\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}